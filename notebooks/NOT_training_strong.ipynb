{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/iamalexkorotin/NeuralOptimalTransport"
      ],
      "metadata": {
        "id": "8yQAbbztiU--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('NeuralOptimalTransport')"
      ],
      "metadata": {
        "id": "iXFXhVpUiXmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cuda"
      ],
      "metadata": {
        "id": "Cw0lzNRM0VYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt\n",
        "!pip install wandb\n",
        "!pip install pot"
      ],
      "metadata": {
        "id": "XvO-n93gieeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0fB7XEiiRBj"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import gc\n",
        "\n",
        "from src import distributions\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from src.resnet2 import ResNet_D\n",
        "from src.unet import UNet\n",
        "\n",
        "from src.tools import unfreeze, freeze\n",
        "from src.tools import weights_init_D\n",
        "from src.tools import load_dataset, get_pushed_loader_stats\n",
        "from src.fid_score import calculate_frechet_distance\n",
        "from src.plotters import plot_random_images, plot_images\n",
        "\n",
        "from copy import deepcopy\n",
        "import json\n",
        "\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import wandb # <--- online logging of the results\n",
        "from src.tools import fig2data, fig2img # for wandb\n",
        "\n",
        "# This needed to use dataloaders for some datasets\n",
        "from PIL import PngImagePlugin\n",
        "LARGE_ENOUGH_NUMBER = 100\n",
        "PngImagePlugin.MAX_TEXT_CHUNK = LARGE_ENOUGH_NUMBER * (1024**2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMKyO4UaiRBl"
      },
      "source": [
        "## Main Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "parameters"
        ],
        "id": "Q2vasM2UiRBn"
      },
      "outputs": [],
      "source": [
        "DEVICE_IDS = [0]\n",
        "\n",
        "#DATASET1, DATASET1_PATH = 'handbag', '../../data/handbag_128.hdf5'\n",
        "#DATASET2, DATASET2_PATH = 'shoes', '../../data/shoes_128.hdf5'\n",
        "\n",
        "DATASET1, DATASET1_PATH = 'celeba_female', 'data/img-align-celeba'\n",
        "DATASET2, DATASET2_PATH = 'celeba_male', 'data/img-align-celeba'\n",
        "\n",
        "T_ITERS = 10\n",
        "f_LR, T_LR = 1e-4, 1e-4\n",
        "IMG_SIZE = 64\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "PLOT_INTERVAL = 100\n",
        "COST = 'mse' # Mean Squared Error\n",
        "CPKT_INTERVAL = 2000\n",
        "MAX_STEPS = 100001\n",
        "SEED = 0x000000\n",
        "\n",
        "EXP_NAME = f'{DATASET1}_{DATASET2}_T{T_ITERS}_{COST}_{IMG_SIZE}'\n",
        "OUTPUT_PATH = '../checkpoints/{}/{}_{}_{}/'.format(COST, DATASET1, DATASET2, IMG_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMguKYK0iRBn"
      },
      "source": [
        "## Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLTiWPSMiRBo"
      },
      "outputs": [],
      "source": [
        "config = dict(\n",
        "    DATASET1=DATASET1,\n",
        "    DATASET2=DATASET2,\n",
        "    T_ITERS=T_ITERS,\n",
        "    f_LR=f_LR, T_LR=T_LR,\n",
        "    BATCH_SIZE=BATCH_SIZE\n",
        ")\n",
        "\n",
        "assert torch.cuda.is_available()\n",
        "torch.cuda.set_device(f'cuda:{DEVICE_IDS[0]}')\n",
        "torch.manual_seed(SEED); np.random.seed(SEED)\n",
        "\n",
        "if not os.path.exists(OUTPUT_PATH):\n",
        "    os.makedirs(OUTPUT_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ipuBXj9iRBp"
      },
      "source": [
        "## Loading data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir(\"data\")\n",
        "os.chdir(\"data\")"
      ],
      "metadata": {
        "id": "9PfYsWwdkCKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q opendatasets\n",
        "\n",
        "import opendatasets as od\n",
        "import pandas as pd\n",
        "\n",
        "kaggle_id = {\"username\":\"your_username_here\",\"key\":\"your_kaggle_key_here\"}\n",
        "od.download('https://www.kaggle.com/datasets/yunting0123/img-align-celeba')"
      ],
      "metadata": {
        "id": "dMroFB02kD99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(\"../\")"
      ],
      "metadata": {
        "id": "rXcKxFGCkR7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYwYQ2h2iRBp"
      },
      "source": [
        "## Prepare Samplers (X, Y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Subset, DataLoader\n",
        "from torchvision.transforms import Compose, Resize, Normalize, ToTensor, RandomCrop\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "\n",
        "def load_dataset(name, path, img_size=64, batch_size=64, test_ratio=0.1, device='cuda'):\n",
        "    if name in ['shoes', 'handbag', 'outdoor', 'church']:\n",
        "        dataset = h5py_to_dataset(path, img_size)\n",
        "    elif name in ['celeba_female', 'celeba_male', 'aligned_anime_faces', 'describable_textures']:\n",
        "        transform = Compose([Resize((img_size, img_size)), ToTensor(), Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "        dataset = ImageFolder(path, transform=transform)\n",
        "    else:\n",
        "        raise Exception('Unknown dataset')\n",
        "\n",
        "    if name in ['celeba_female', 'celeba_male']:\n",
        "        with open('datasets/list_attr_celeba.txt', 'r') as f:\n",
        "            lines = f.readlines()[2:]\n",
        "        if name == 'celeba_female':\n",
        "            idx = [i for i in list(range(len(lines))) if lines[i].replace('  ', ' ').split(' ')[21] == '-1']\n",
        "        else:\n",
        "            idx = [i for i in list(range(len(lines))) if lines[i].replace('  ', ' ').split(' ')[21] != '-1']\n",
        "    elif dataset == 'describable_textures':\n",
        "        idx = np.random.RandomState(seed=0xBADBEEF).permutation(len(dataset))\n",
        "    else:\n",
        "        idx = list(range(len(dataset)))\n",
        "\n",
        "    test_size = int(len(idx) * test_ratio)\n",
        "    train_idx, test_idx = idx[:-test_size], idx[-test_size:]\n",
        "    train_set, test_set = Subset(dataset, train_idx), Subset(dataset, test_idx)\n",
        "\n",
        "    train_sampler = distributions.LoaderSampler(DataLoader(train_set, shuffle=True, num_workers=8, batch_size=batch_size), device)\n",
        "    test_sampler = distributions.LoaderSampler(DataLoader(test_set, shuffle=True, num_workers=8, batch_size=batch_size), device)\n",
        "    return train_sampler, test_sampler"
      ],
      "metadata": {
        "id": "DNCfiZ9qlGiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2nNYCTviRBq"
      },
      "outputs": [],
      "source": [
        "X_sampler, X_test_sampler = load_dataset(DATASET1, DATASET1_PATH, img_size=IMG_SIZE)\n",
        "Y_sampler, Y_test_sampler = load_dataset(DATASET2, DATASET2_PATH, img_size=IMG_SIZE)\n",
        "\n",
        "torch.cuda.empty_cache(); gc.collect()\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Veb7gabDiRBr"
      },
      "source": [
        "# Initializing Networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9l-OuexbiRBr"
      },
      "outputs": [],
      "source": [
        "f = ResNet_D(IMG_SIZE, nc=3).cuda()\n",
        "f.apply(weights_init_D)\n",
        "\n",
        "T = UNet(3, 3, base_factor=48).cuda()\n",
        "\n",
        "if len(DEVICE_IDS) > 1:\n",
        "    T = nn.DataParallel(T, device_ids=DEVICE_IDS)\n",
        "    f = nn.DataParallel(f, device_ids=DEVICE_IDS)\n",
        "\n",
        "print('T params:', np.sum([np.prod(p.shape) for p in T.parameters()]))\n",
        "print('f params:', np.sum([np.prod(p.shape) for p in f.parameters()]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SpjRfK6iRBs"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0xBADBEEF); np.random.seed(0xBADBEEF)\n",
        "X_fixed = X_sampler.sample(10)\n",
        "Y_fixed = Y_sampler.sample(10)\n",
        "X_test_fixed = X_test_sampler.sample(10)\n",
        "Y_test_fixed = Y_test_sampler.sample(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrn_QnnxiRBs"
      },
      "source": [
        "### Plots Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "9UY-HSZTiRBt"
      },
      "outputs": [],
      "source": [
        "fig, axes = plot_images(X_fixed, Y_fixed, T)\n",
        "fig, axes = plot_random_images(X_sampler, Y_sampler, T)\n",
        "fig, axes = plot_images(X_test_fixed, Y_test_fixed, T)\n",
        "fig, axes = plot_random_images(X_test_sampler, Y_test_sampler, T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6lrUrUfiRBt"
      },
      "source": [
        "# Run Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRXQC3RWiRBt"
      },
      "outputs": [],
      "source": [
        "#wandb.init(name=EXP_NAME, project='notreallyweakot', entity='gunsandroses', config=config)\n",
        "#pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PAWec394iRBu"
      },
      "outputs": [],
      "source": [
        "T_opt = torch.optim.Adam(T.parameters(), lr=T_LR, weight_decay=1e-10)\n",
        "f_opt = torch.optim.Adam(f.parameters(), lr=f_LR, weight_decay=1e-10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "_q8tmga_iRBu"
      },
      "outputs": [],
      "source": [
        "for step in tqdm(range(MAX_STEPS)):\n",
        "    # T optimization\n",
        "    unfreeze(T); freeze(f)\n",
        "    for t_iter in range(T_ITERS):\n",
        "        T_opt.zero_grad()\n",
        "        X = X_sampler.sample(BATCH_SIZE)\n",
        "        T_X = T(X)\n",
        "        if COST == 'mse':\n",
        "            T_loss = F.mse_loss(X, T_X).mean() - f(T_X).mean()\n",
        "        else:\n",
        "            raise Exception('Unknown COST')\n",
        "        T_loss.backward(); T_opt.step()\n",
        "    del T_loss, T_X, X; gc.collect(); torch.cuda.empty_cache()\n",
        "\n",
        "    # f optimization\n",
        "    freeze(T); unfreeze(f)\n",
        "    X = X_sampler.sample(BATCH_SIZE)\n",
        "    with torch.no_grad():\n",
        "        T_X = T(X)\n",
        "    Y = Y_sampler.sample(BATCH_SIZE)\n",
        "    f_opt.zero_grad()\n",
        "    f_loss = f(T_X).mean() - f(Y).mean()\n",
        "    f_loss.backward(); f_opt.step();\n",
        "    #wandb.log({f'f_loss' : f_loss.item()}, step=step)\n",
        "    del f_loss, Y, X, T_X; gc.collect(); torch.cuda.empty_cache()\n",
        "\n",
        "    if step % PLOT_INTERVAL == 0:\n",
        "        print('Plotting')\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        fig, axes = plot_images(X_fixed, Y_fixed, T)\n",
        "        #wandb.log({'Fixed Images' : [wandb.Image(fig2img(fig))]}, step=step)\n",
        "        plt.show(fig); plt.close(fig)\n",
        "\n",
        "        fig, axes = plot_random_images(X_sampler,  Y_sampler, T)\n",
        "        #wandb.log({'Random Images' : [wandb.Image(fig2img(fig))]}, step=step)\n",
        "        plt.show(fig); plt.close(fig)\n",
        "\n",
        "        fig, axes = plot_images(X_test_fixed, Y_test_fixed, T)\n",
        "        #wandb.log({'Fixed Test Images' : [wandb.Image(fig2img(fig))]}, step=step)\n",
        "        plt.show(fig); plt.close(fig)\n",
        "\n",
        "        fig, axes = plot_random_images(X_test_sampler, Y_test_sampler, T)\n",
        "        #wandb.log({'Random Test Images' : [wandb.Image(fig2img(fig))]}, step=step)\n",
        "        plt.show(fig); plt.close(fig)\n",
        "\n",
        "    if step % CPKT_INTERVAL == CPKT_INTERVAL - 1:\n",
        "        freeze(T);\n",
        "\n",
        "        print('Computing FID')\n",
        "        mu, sigma = get_pushed_loader_stats(T, X_test_sampler.loader)\n",
        "        fid = calculate_frechet_distance(mu_data, sigma_data, mu, sigma)\n",
        "        #wandb.log({f'FID (Test)' : fid}, step=step)\n",
        "        del mu, sigma\n",
        "\n",
        "        torch.save(T.state_dict(), os.path.join(OUTPUT_PATH, f'{SEED}_{step}.pt'))\n",
        "#         torch.save(f.state_dict(), os.path.join(OUTPUT_PATH, f'f_{SEED}_{step}.pt'))\n",
        "#         torch.save(f_opt.state_dict(), os.path.join(OUTPUT_PATH, f'f_opt_{SEED}_{step}.pt'))\n",
        "#         torch.save(T_opt.state_dict(), os.path.join(OUTPUT_PATH, f'T_opt_{SEED}_{step}.pt'))\n",
        "\n",
        "    gc.collect(); torch.cuda.empty_cache()"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Tags",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}